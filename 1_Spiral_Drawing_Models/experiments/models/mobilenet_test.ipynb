{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d9750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import mobilenet_v3_large \n",
    "from torchinfo import summary\n",
    "\n",
    "mobilenet_model = mobilenet_v3_large(weights = \"DEFAULT\")\n",
    "summary(mobilenet_model, \n",
    "        input_size=(1, 3, 224, 224), # (batch, C = 3, H, W)\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee76fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d92a54cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, inference_mode\n",
    "\n",
    "# These steps must be followed in this exact order\n",
    "# -------------------------------------------------\n",
    "\n",
    "# 1. get the pretraind weights of the original conv2d block (input)\n",
    "old_conv = mobilenet_model.features[0][0] # Conv2d inside Conv2dNormActivation\n",
    "\n",
    "# 2. create the new conv2d input block, change the input to take 1 channel only (grayscale)\n",
    "new_conv = nn.Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "\n",
    "# 3. average the rgb weights across channels to form one grayscale channel\n",
    "with inference_mode():\n",
    "    new_conv.weight[:] = old_conv.weight.mean(dim=1, keepdim=True)\n",
    "    if old_conv.bias is not None:\n",
    "        new_conv.bias[:] = old_conv.bias\n",
    "    \n",
    "# 4. replace the input block\n",
    "mobilenet_model.features[0][0] = new_conv\n",
    "\n",
    "# 5. freeze model\n",
    "for param in mobilenet_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# change the output to 2 classes only (healthy, pd)\n",
    "# this only unfreezes this block\n",
    "mobilenet_model.classifier[3] = nn.Linear(in_features=1280, out_features=1, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bdbc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(mobilenet_model, \n",
    "        input_size=(1, 1, 512, 512), # (batch, C = 1, H, W)\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96682d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_mobilenetV3 import create_mobilenetv3\n",
    "from torchinfo import summary\n",
    "\n",
    "model = create_mobilenetv3()\n",
    "summary(model, \n",
    "        input_size=(1, 1, 512, 512), # (batch, C = 1, H, W)\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
