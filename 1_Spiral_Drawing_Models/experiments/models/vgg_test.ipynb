{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba5efd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vgg19_bn # may try more vgg archs\n",
    "from torchinfo import summary\n",
    "\n",
    "vgg_model = vgg19_bn(weights = \"DEFAULT\")\n",
    "summary(vgg_model, \n",
    "        input_size=(1, 3, 512, 512), # (batch, C = 3, H, W)\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa88c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00cca629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, inference_mode\n",
    "\n",
    "# These steps must be followed in this exact order\n",
    "# -------------------------------------------------\n",
    "\n",
    "# 1. get the pretraind weights of the original conv2d block (input)\n",
    "old_conv = vgg_model.features[0]\n",
    "\n",
    "# 2. create the new conv2d input block, change the input to take 1 channel only (grayscale)\n",
    "new_conv = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "\n",
    "# 3. average the rgb weights across channels to form one grayscale channel\n",
    "with inference_mode():\n",
    "    new_conv.weight = nn.Parameter(old_conv.weight.mean(dim=1, keepdim=True))\n",
    "    if old_conv.bias is not None:\n",
    "        new_conv.bias = old_conv.bias\n",
    "    \n",
    "# 4. replace the input block\n",
    "vgg_model.features[0] = new_conv\n",
    "\n",
    "# 5. freeze model\n",
    "for param in vgg_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# change the output to 2 classes only (healthy, pd)\n",
    "# this only unfreezes this block\n",
    "vgg_model.classifier[-1] = nn.Linear(in_features=4096, out_features=2, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e2cc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(vgg_model, \n",
    "        input_size=(1, 1, 224, 224), # (batch, C = 1, H, W)\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7853298c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_vgg19_bn import create_vgg\n",
    "from torchinfo import summary\n",
    "\n",
    "model = create_vgg()\n",
    "summary(model, \n",
    "        input_size=(1, 1, 224, 224), # (batch, C = 1, H, W)\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed5c23c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
