{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139236bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vit_b_16\n",
    "from torchinfo import summary\n",
    "\n",
    "vit_model = vit_b_16(weights = \"DEFAULT\")\n",
    "summary(vit_model, \n",
    "        input_size=(1, 3, 224, 224), # (batch, C = 3, H, W)\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4362453",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_model # get input and output functions from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bf946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, inference_mode\n",
    "\n",
    "# These steps must be followed in this exact order\n",
    "# -------------------------------------------------\n",
    "\n",
    "# 1. get the pretraind weights of the original conv2d block (input)\n",
    "old_conv = vit_model.conv_proj\n",
    "\n",
    "# 2. create the new conv2d input block, change the input to take 1 channel only (grayscale)\n",
    "new_conv = nn.Conv2d(1, 768, kernel_size=(16, 16), stride=(16, 16))\n",
    "\n",
    "# 3. average the rgb weights across channels to form one grayscale channel\n",
    "with inference_mode():\n",
    "    new_conv.weight[:] = old_conv.weight.mean(dim=1, keepdim=True)\n",
    "    new_conv.bias[:] = old_conv.bias\n",
    "    \n",
    "# 4. replace the input block\n",
    "vit_model.conv_proj = new_conv\n",
    "\n",
    "# 5. freeze model\n",
    "for param in vit_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# change the output to 2 classes only (healthy, pd)\n",
    "# this only unfreezes this block\n",
    "vit_model.heads = nn.Sequential(\n",
    "    nn.Linear(in_features=768, out_features=2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a642f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(vit_model, \n",
    "        input_size=(1, 1, 224, 224), # (batch, C = 1 , H, W)\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cb8c496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassification(\n",
       "    crop_size=[224]\n",
       "    resize_size=[256]\n",
       "    mean=[0.485, 0.456, 0.406]\n",
       "    std=[0.229, 0.224, 0.225]\n",
       "    interpolation=InterpolationMode.BILINEAR\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import ViT_B_16_Weights\n",
    "ViT_B_16_Weights.DEFAULT.transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5795a69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_Vit_b16 import create_vit\n",
    "from torchinfo import summary\n",
    "\n",
    "model = create_vit()\n",
    "\n",
    "summary(model, \n",
    "        input_size=(1, 1, 224, 224), # (batch, C = 1 , H, W)\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388d3f77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
